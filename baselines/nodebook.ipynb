{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-02T08:16:32.153381Z",
     "start_time": "2025-03-02T08:16:32.139841Z"
    }
   },
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "# 这个笔记本的目的就是随手弄一点需要验证的东西\n",
    "def batch_block_shuffle_augmentation(x, block_size=3, swap_ratio=0.2):\n",
    "    \"\"\"\n",
    "    批量时间序列块随机交换增强方法\n",
    "    Args:\n",
    "        x (Tensor): 输入时间序列，形状 (batch_size, T)\n",
    "        block_size (int): 每块的时间步数，默认为3\n",
    "        swap_ratio (float): 交换块的比例（0~1），默认为0.2\n",
    "    Returns:\n",
    "        Tensor: 增强后的时间序列，形状 (batch_size, T)\n",
    "    \"\"\"\n",
    "    batch_size, T = x.shape\n",
    "\n",
    "    # 1. 填充到块大小的整数倍\n",
    "    remainder = T % block_size\n",
    "    if remainder != 0:\n",
    "        padding = block_size - remainder\n",
    "        x_padded = torch.nn.functional.pad(x, (0, padding))\n",
    "    else:\n",
    "        x_padded = x\n",
    "\n",
    "    # 2. 分块 (batch_size, num_blocks, block_size)\n",
    "    num_blocks = x_padded.size(1) // block_size\n",
    "    blocks = x_padded.view(batch_size, num_blocks, block_size)\n",
    "    print(\"patchified\", blocks)\n",
    "    # 3. 为每个样本生成独立的随机排列和掩码\n",
    "    # 生成随机排列索引 (batch_size, num_blocks)\n",
    "    perm = torch.argsort(torch.rand(batch_size, num_blocks, device=x.device), dim=-1)\n",
    "\n",
    "    # 生成交换掩码 (batch_size, num_blocks)\n",
    "    mask = torch.rand(batch_size, num_blocks, device=x.device) < swap_ratio\n",
    "    print(mask, perm)\n",
    "    # 原始块索引 (0, 1, ..., num_blocks-1)\n",
    "    original_indices = torch.arange(num_blocks, device=x.device).expand(batch_size, -1)\n",
    "\n",
    "    # 4. 计算新索引\n",
    "    new_indices = torch.where(mask, perm, original_indices)\n",
    "\n",
    "    # 5. 使用高级索引重组块\n",
    "    batch_idx = torch.arange(batch_size, device=x.device)[:, None]\n",
    "    print(\"batch_idx\", batch_idx)\n",
    "    shuffled_blocks = blocks[batch_idx, new_indices]\n",
    "\n",
    "    # 6. 展平并截断填充部分\n",
    "    shuffled_x = shuffled_blocks.reshape(batch_size, -1)\n",
    "    if remainder != 0:\n",
    "        shuffled_x = shuffled_x[:, :T]\n",
    "\n",
    "    return shuffled_x\n",
    "x = torch.tensor([[i for i in range(12)], [i for i in range(12)]], dtype=torch.float32)\n",
    "print(\"原始序列:\\n\", x)\n",
    "\n",
    "# 应用增强（交换比例0.5）\n",
    "augmented = batch_block_shuffle_augmentation(x, swap_ratio=0.25)\n",
    "print(\"增强后序列:\\n\", augmented)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始序列:\n",
      " tensor([[ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11.],\n",
      "        [ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11.]])\n",
      "patchified tensor([[[ 0.,  1.,  2.],\n",
      "         [ 3.,  4.,  5.],\n",
      "         [ 6.,  7.,  8.],\n",
      "         [ 9., 10., 11.]],\n",
      "\n",
      "        [[ 0.,  1.,  2.],\n",
      "         [ 3.,  4.,  5.],\n",
      "         [ 6.,  7.,  8.],\n",
      "         [ 9., 10., 11.]]])\n",
      "tensor([[False,  True, False, False],\n",
      "        [False, False, False, False]]) tensor([[3, 2, 0, 1],\n",
      "        [2, 1, 0, 3]])\n",
      "batch_idx tensor([[0],\n",
      "        [1]])\n",
      "增强后序列:\n",
      " tensor([[ 0.,  1.,  2.,  6.,  7.,  8.,  6.,  7.,  8.,  9., 10., 11.],\n",
      "        [ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11.]])\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-02T09:00:27.249363Z",
     "start_time": "2025-03-02T09:00:27.238724Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def process_sequence(seq: torch.Tensor, block_size=2, p=0.5):\n",
    "    \"\"\"\n",
    "    :param seq: 输入的序列，形如(AnyShape, T,)\n",
    "    \"\"\"\n",
    "    # note 先创建新的输出的位置，并且进行分块\n",
    "    original_shape = seq.shape\n",
    "    length = original_shape[-1]\n",
    "    count_blocks = length // block_size\n",
    "    blocks = seq.reshape(-1, count_blocks, block_size)\n",
    "    print(blocks.shape)\n",
    "    bs = blocks.shape[0]\n",
    "    # (bs(B, N), count_blocks, block_size)\n",
    "    new_blocks = blocks.clone()\n",
    "    # 选择并打乱块\n",
    "    for i in range(bs):\n",
    "        selected_mask = torch.rand(count_blocks) < p\n",
    "        selected_indices = torch.where(selected_mask)[0]\n",
    "        shuffled_indices = selected_indices[torch.randperm(len(selected_indices))]\n",
    "        new_blocks[i][selected_indices] = blocks[i][shuffled_indices]\n",
    "\n",
    "    # 合并\n",
    "    return new_blocks.reshape(original_shape)  # 去除填充部分（如有）\n",
    "\n",
    "\n",
    "seq = torch.Tensor([[i for i in range(12)], [i for i in range(12)]])\n",
    "print(seq)\n",
    "preprocessed_seq = process_sequence(seq)\n",
    "print(preprocessed_seq)"
   ],
   "id": "f85b486690c9d5b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11.],\n",
      "        [ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11.]])\n",
      "torch.Size([2, 6, 2])\n",
      "tensor([[ 0.,  1.,  4.,  5.,  6.,  7.,  2.,  3.,  8.,  9., 10., 11.],\n",
      "        [ 8.,  9.,  4.,  5.,  2.,  3.,  0.,  1.,  6.,  7., 10., 11.]])\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-02T08:48:06.841958Z",
     "start_time": "2025-03-02T08:48:06.797588Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "def permutation(x, max_segments=5, seg_mode=\"random\"):\n",
    "    \"\"\"\n",
    "    :param x 形如(batch_size, N, T)\n",
    "    \"\"\"\n",
    "    orig_steps = np.arange(x.shape[2])\n",
    "    x = x.cpu().numpy()\n",
    "    num_segs = np.random.randint(1, max_segments, size=(x.shape[0]))\n",
    "    print(num_segs)\n",
    "    ret = np.zeros_like(x)\n",
    "    for i, pat in enumerate(x):\n",
    "        if num_segs[i] > 1:\n",
    "            if seg_mode == \"random\":\n",
    "                split_points = np.random.choice(x.shape[2] - 2, num_segs[i] - 1, replace=False)\n",
    "                split_points.sort()\n",
    "                splits = np.split(orig_steps, split_points)\n",
    "            else:\n",
    "                splits = np.array_split(orig_steps, num_segs[i])\n",
    "            warp = np.concatenate(np.random.permutation(splits)).ravel()\n",
    "            ret[i] = pat[0, warp]\n",
    "        else:\n",
    "            ret[i] = pat\n",
    "    return torch.from_numpy(ret)\n",
    "ts = torch.Tensor([[[i for i in range(12)]]])\n",
    "\n",
    "print(permutation(ts))ss"
   ],
   "id": "15a13d3a36a8a7e2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (3,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[21], line 23\u001B[0m\n\u001B[1;32m     20\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mfrom_numpy(ret)\n\u001B[1;32m     21\u001B[0m ts \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mTensor([[[i \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m12\u001B[39m)]]])\n\u001B[0;32m---> 23\u001B[0m \u001B[38;5;28mprint\u001B[39m(permutation(ts))\n",
      "Cell \u001B[0;32mIn[21], line 16\u001B[0m, in \u001B[0;36mpermutation\u001B[0;34m(x, max_segments, seg_mode)\u001B[0m\n\u001B[1;32m     14\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     15\u001B[0m         splits \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marray_split(orig_steps, num_segs[i])\n\u001B[0;32m---> 16\u001B[0m     warp \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mconcatenate(np\u001B[38;5;241m.\u001B[39mrandom\u001B[38;5;241m.\u001B[39mpermutation(splits))\u001B[38;5;241m.\u001B[39mravel()\n\u001B[1;32m     17\u001B[0m     ret[i] \u001B[38;5;241m=\u001B[39m pat[\u001B[38;5;241m0\u001B[39m, warp]\n\u001B[1;32m     18\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[0;32mnumpy/random/mtrand.pyx:4720\u001B[0m, in \u001B[0;36mnumpy.random.mtrand.RandomState.permutation\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;31mValueError\u001B[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (3,) + inhomogeneous part."
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-02T09:31:16.347710Z",
     "start_time": "2025-03-02T09:31:16.337525Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def process_sequence(seq: torch.Tensor, block_size=2, p=0.5):\n",
    "    \"\"\"\n",
    "    :param seq: 输入的序列，形如(B, T, N)\n",
    "    \"\"\"\n",
    "    # note 先创建新的输出的位置，并且进行分块\n",
    "    original_shape = seq.shape\n",
    "    bs = seq.shape[0]\n",
    "    seq_length = original_shape[-2]\n",
    "    count_nodes = seq.shape[-1]\n",
    "\n",
    "    count_blocks = seq_length // block_size\n",
    "    blocks = seq.reshape(-1, count_blocks, block_size, count_nodes)\n",
    "    # (bs(B, N), count_blocks, block_size)\n",
    "    new_blocks = blocks.clone()\n",
    "    # 选择并打乱块\n",
    "    for i in range(bs):\n",
    "        selected_mask = torch.rand(count_blocks) < p\n",
    "        selected_indices = torch.where(selected_mask)[0]\n",
    "        shuffled_indices = selected_indices[torch.randperm(len(selected_indices))]\n",
    "        new_blocks[i][selected_indices] = blocks[i][shuffled_indices]\n",
    "    # 合并\n",
    "    return new_blocks.reshape(original_shape)  # 去除填充部分（如有）\n",
    "b = 2\n",
    "n = 4\n",
    "t = 12\n",
    "input_series = torch.Tensor([[[i for i in range(12)]for __ in range(n)]for _ in range(b)])\n",
    "input_series = torch.transpose(input_series, 1, 2)\n",
    "print(input_series, input_series.shape)\n",
    "print(process_sequence(input_series))"
   ],
   "id": "aa0fcc63cf4a713f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.,  0.,  0.,  0.],\n",
      "         [ 1.,  1.,  1.,  1.],\n",
      "         [ 2.,  2.,  2.,  2.],\n",
      "         [ 3.,  3.,  3.,  3.],\n",
      "         [ 4.,  4.,  4.,  4.],\n",
      "         [ 5.,  5.,  5.,  5.],\n",
      "         [ 6.,  6.,  6.,  6.],\n",
      "         [ 7.,  7.,  7.,  7.],\n",
      "         [ 8.,  8.,  8.,  8.],\n",
      "         [ 9.,  9.,  9.,  9.],\n",
      "         [10., 10., 10., 10.],\n",
      "         [11., 11., 11., 11.]],\n",
      "\n",
      "        [[ 0.,  0.,  0.,  0.],\n",
      "         [ 1.,  1.,  1.,  1.],\n",
      "         [ 2.,  2.,  2.,  2.],\n",
      "         [ 3.,  3.,  3.,  3.],\n",
      "         [ 4.,  4.,  4.,  4.],\n",
      "         [ 5.,  5.,  5.,  5.],\n",
      "         [ 6.,  6.,  6.,  6.],\n",
      "         [ 7.,  7.,  7.,  7.],\n",
      "         [ 8.,  8.,  8.,  8.],\n",
      "         [ 9.,  9.,  9.,  9.],\n",
      "         [10., 10., 10., 10.],\n",
      "         [11., 11., 11., 11.]]]) torch.Size([2, 12, 4])\n",
      "tensor([[[ 8.,  8.,  8.,  8.],\n",
      "         [ 9.,  9.,  9.,  9.],\n",
      "         [ 2.,  2.,  2.,  2.],\n",
      "         [ 3.,  3.,  3.,  3.],\n",
      "         [ 4.,  4.,  4.,  4.],\n",
      "         [ 5.,  5.,  5.,  5.],\n",
      "         [ 6.,  6.,  6.,  6.],\n",
      "         [ 7.,  7.,  7.,  7.],\n",
      "         [ 0.,  0.,  0.,  0.],\n",
      "         [ 1.,  1.,  1.,  1.],\n",
      "         [10., 10., 10., 10.],\n",
      "         [11., 11., 11., 11.]],\n",
      "\n",
      "        [[ 6.,  6.,  6.,  6.],\n",
      "         [ 7.,  7.,  7.,  7.],\n",
      "         [ 2.,  2.,  2.,  2.],\n",
      "         [ 3.,  3.,  3.,  3.],\n",
      "         [ 0.,  0.,  0.,  0.],\n",
      "         [ 1.,  1.,  1.,  1.],\n",
      "         [ 8.,  8.,  8.,  8.],\n",
      "         [ 9.,  9.,  9.,  9.],\n",
      "         [ 4.,  4.,  4.,  4.],\n",
      "         [ 5.,  5.,  5.,  5.],\n",
      "         [10., 10., 10., 10.],\n",
      "         [11., 11., 11., 11.]]])\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "3747fc58a4039fa1"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
